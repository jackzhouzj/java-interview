# Flink å®Œæ•´æ•™ç¨‹

## ğŸ“‹ ç›®å½•
- [æŠ€æœ¯æ¦‚è¿°](#æŠ€æœ¯æ¦‚è¿°)
- [å­¦ä¹ ç›®æ ‡](#å­¦ä¹ ç›®æ ‡)
- [åŸºç¡€æ¦‚å¿µ](#åŸºç¡€æ¦‚å¿µ)
- [æ ¸å¿ƒç‰¹æ€§](#æ ¸å¿ƒç‰¹æ€§)
- [å®æˆ˜åº”ç”¨](#å®æˆ˜åº”ç”¨)
- [æœ€ä½³å®è·µ](#æœ€ä½³å®è·µ)
- [å¸¸è§é—®é¢˜](#å¸¸è§é—®é¢˜)
- [ç›¸å…³èµ„æº](#ç›¸å…³èµ„æº)

## ğŸ“š æŠ€æœ¯æ¦‚è¿°

- **ç‰ˆæœ¬**: 1.18.0 (æœ€æ–°ç¨³å®šç‰ˆ)
- **å®˜æ–¹æ–‡æ¡£**: https://flink.apache.org/
- **å­¦ä¹ éš¾åº¦**: â­â­â­â­â­ (5/5æ˜Ÿ)
- **é‡è¦ç¨‹åº¦**: â­â­â­â­ (4/5æ˜Ÿ)
- **å‰ç½®çŸ¥è¯†**: 
  - JavaåŸºç¡€
  - æµå¤„ç†æ¦‚å¿µ
  - åˆ†å¸ƒå¼ç³»ç»ŸåŸç†
  - äº‹ä»¶é©±åŠ¨æ¶æ„

**æ–‡æ¡£æ¥æº**: Apache Flinkå®˜æ–¹æ–‡æ¡£ (Context7)

## ğŸ¯ å­¦ä¹ ç›®æ ‡

- [ ] ç†è§£Flinkçš„æ ¸å¿ƒæ¶æ„å’Œè®¾è®¡ç†å¿µ
- [ ] æŒæ¡DataStream APIè¿›è¡Œæµå¤„ç†
- [ ] ç†è§£äº‹ä»¶æ—¶é—´å’Œæ°´å°æœºåˆ¶
- [ ] æŒæ¡çª—å£æ“ä½œå’ŒçŠ¶æ€ç®¡ç†
- [ ] äº†è§£Flinkçš„å®¹é”™æœºåˆ¶
- [ ] æŒæ¡Flinkæ€§èƒ½ä¼˜åŒ–æŠ€å·§
- [ ] èƒ½å¤Ÿåœ¨Javaé¡¹ç›®ä¸­é›†æˆFlink

## ğŸ“– åŸºç¡€æ¦‚å¿µ

### 1.1 ä»€ä¹ˆæ˜¯Flink

Apache Flinkæ˜¯ä¸€ä¸ªåˆ†å¸ƒå¼æµå¤„ç†æ¡†æ¶ï¼Œä¸“ä¸ºæœ‰çŠ¶æ€çš„æµå¤„ç†å’Œæ‰¹å¤„ç†è€Œè®¾è®¡ã€‚å®ƒçš„æ ¸å¿ƒç‰¹ç‚¹æ˜¯ï¼š

- **çœŸæµå¤„ç†**: åŸºäºäº‹ä»¶é©±åŠ¨çš„æµå¤„ç†ï¼Œè€Œéå¾®æ‰¹å¤„ç†
- **ä½å»¶è¿Ÿ**: æ¯«ç§’çº§å»¶è¿Ÿï¼Œé€‚åˆå®æ—¶åœºæ™¯
- **é«˜åå**: æ¯ç§’å¤„ç†ç™¾ä¸‡çº§äº‹ä»¶
- **ç²¾ç¡®ä¸€æ¬¡**: Exactly-Onceè¯­ä¹‰ä¿è¯
- **äº‹ä»¶æ—¶é—´**: æ”¯æŒäº‹ä»¶æ—¶é—´å’Œä¹±åºå¤„ç†
- **æœ‰çŠ¶æ€è®¡ç®—**: å¼ºå¤§çš„çŠ¶æ€ç®¡ç†èƒ½åŠ›

### 1.2 Flink vs Spark Streaming

| ç‰¹æ€§ | Flink | Spark Streaming |
|------|-------|-----------------|
| å¤„ç†æ¨¡å‹ | çœŸæµå¤„ç† | å¾®æ‰¹å¤„ç† |
| å»¶è¿Ÿ | æ¯«ç§’çº§ | ç§’çº§ |
| ååé‡ | é«˜ | æ›´é«˜ |
| çŠ¶æ€ç®¡ç† | å¼ºå¤§ | è¾ƒå¼± |
| äº‹ä»¶æ—¶é—´ | åŸç”Ÿæ”¯æŒ | éœ€è¦é¢å¤–é…ç½® |
| å®¹é”™æœºåˆ¶ | Checkpoint | RDDè¡€ç»Ÿ |
| å­¦ä¹ æ›²çº¿ | é™¡å³­ | å¹³ç¼“ |

### 1.3 Flinkæ¶æ„

```
Client (æäº¤ä½œä¸š)
  â†“
JobManager (åè°ƒè€…)
  â†“
TaskManager1  TaskManager2  TaskManager3 (å·¥ä½œèŠ‚ç‚¹)
  â†“
Task Slot (ä»»åŠ¡æ§½)
```

**æ ¸å¿ƒç»„ä»¶**:
- **JobManager**: åè°ƒåˆ†å¸ƒå¼æ‰§è¡Œï¼Œç®¡ç†Checkpoint
- **TaskManager**: æ‰§è¡Œå…·ä½“çš„ä»»åŠ¡ï¼Œç®¡ç†å†…å­˜å’Œç½‘ç»œ
- **Task Slot**: èµ„æºéš”ç¦»å•å…ƒï¼Œæ¯ä¸ªSlotè¿è¡Œä¸€ä¸ªå¹¶è¡Œä»»åŠ¡

### 1.4 åº”ç”¨åœºæ™¯

- **å®æ—¶æ•°æ®åˆ†æ**: å®æ—¶ç›‘æ§ã€å®æ—¶æŠ¥è¡¨
- **äº‹ä»¶é©±åŠ¨åº”ç”¨**: æ¬ºè¯ˆæ£€æµ‹ã€å¼‚å¸¸æ£€æµ‹
- **å®æ—¶ETL**: æ•°æ®æ¸…æ´—ã€è½¬æ¢ã€åŠ è½½
- **æµå¼æœºå™¨å­¦ä¹ **: åœ¨çº¿å­¦ä¹ ã€å®æ—¶é¢„æµ‹
- **å¤æ‚äº‹ä»¶å¤„ç†**: æ¨¡å¼åŒ¹é…ã€è§„åˆ™å¼•æ“

## ğŸ”¥ æ ¸å¿ƒç‰¹æ€§ (é‡ç‚¹)

### 2.1 DataStream API ğŸ”¥

DataStream APIæ˜¯Flinkæµå¤„ç†çš„æ ¸å¿ƒAPIã€‚

#### 2.1.1 åˆ›å»ºDataStream

```java
import org.apache.flink.streaming.api.datastream.DataStream;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;

/**
 * DataStreamåˆ›å»ºç¤ºä¾‹
 * 
 * @author erik.zhou
 */
public class DataStreamCreationExample {
    
    public static void main(String[] args) throws Exception {
        // åˆ›å»ºæ‰§è¡Œç¯å¢ƒ
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        
        // æ–¹å¼1: ä»é›†åˆåˆ›å»º
        DataStream<Integer> stream1 = env.fromElements(1, 2, 3, 4, 5);
        
        // æ–¹å¼2: ä»æ–‡ä»¶åˆ›å»º
        DataStream<String> stream2 = env.readTextFile("data/input.txt");
        
        // æ–¹å¼3: ä»Socketåˆ›å»º
        DataStream<String> stream3 = env.socketTextStream("localhost", 9999);
        
        // æ–¹å¼4: ä»Kafkaåˆ›å»º
        Properties props = new Properties();
        props.setProperty("bootstrap.servers", "localhost:9092");
        props.setProperty("group.id", "flink-consumer");
        
        FlinkKafkaConsumer<String> kafkaSource = new FlinkKafkaConsumer<>(
            "topic-name",
            new SimpleStringSchema(),
            props
        );
        DataStream<String> stream4 = env.addSource(kafkaSource);
        
        // æ–¹å¼5: è‡ªå®šä¹‰Source
        DataStream<String> stream5 = env.addSource(new CustomSourceFunction());
        
        // æ‰§è¡Œ
        env.execute("DataStream Creation");
    }
}
```

#### 2.1.2 DataStreamè½¬æ¢æ“ä½œ

```java
import org.apache.flink.api.common.functions.FilterFunction;
import org.apache.flink.api.common.functions.MapFunction;
import org.apache.flink.api.common.functions.FlatMapFunction;
import org.apache.flink.util.Collector;

/**
 * DataStreamè½¬æ¢æ“ä½œç¤ºä¾‹
 * 
 * @author erik.zhou
 */
public class DataStreamTransformationExample {
    
    public static void main(String[] args) throws Exception {
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        
        DataStream<String> input = env.socketTextStream("localhost", 9999);
        
        // map: ä¸€å¯¹ä¸€è½¬æ¢
        DataStream<Integer> lengths = input.map(new MapFunction<String, Integer>() {
            @Override
            public Integer map(String value) {
                return value.length();
            }
        });
        
        // ä½¿ç”¨Lambdaè¡¨è¾¾å¼
        DataStream<Integer> lengths2 = input.map(String::length);
        
        // filter: è¿‡æ»¤
        DataStream<String> filtered = input.filter(new FilterFunction<String>() {
            @Override
            public boolean filter(String value) {
                return value.startsWith("ERROR");
            }
        });
        
        // flatMap: ä¸€å¯¹å¤šè½¬æ¢
        DataStream<String> words = input.flatMap(new FlatMapFunction<String, String>() {
            @Override
            public void flatMap(String value, Collector<String> out) {
                for (String word : value.split(" ")) {
                    out.collect(word);
                }
            }
        });
        
        // keyBy: æŒ‰keyåˆ†ç»„
        DataStream<Tuple2<String, Integer>> wordCounts = words
            .map(word -> Tuple2.of(word, 1))
            .returns(Types.TUPLE(Types.STRING, Types.INT))
            .keyBy(tuple -> tuple.f0)
            .sum(1);
        
        // union: åˆå¹¶å¤šä¸ªæµ
        DataStream<String> stream1 = env.fromElements("a", "b");
        DataStream<String> stream2 = env.fromElements("c", "d");
        DataStream<String> union = stream1.union(stream2);
        
        // connect: è¿æ¥ä¸¤ä¸ªæµ
        DataStream<Integer> intStream = env.fromElements(1, 2, 3);
        DataStream<String> strStream = env.fromElements("a", "b", "c");
        ConnectedStreams<Integer, String> connected = intStream.connect(strStream);
        
        // split: åˆ†æµ (å·²åºŸå¼ƒï¼Œä½¿ç”¨Side Output)
        
        env.execute("DataStream Transformation");
    }
}
```

### 2.2 äº‹ä»¶æ—¶é—´å’Œæ°´å° (âš ï¸ éš¾ç‚¹)

äº‹ä»¶æ—¶é—´æ˜¯Flinkå¤„ç†ä¹±åºæ•°æ®çš„æ ¸å¿ƒæœºåˆ¶ã€‚

#### 2.2.1 æ—¶é—´è¯­ä¹‰

Flinkæ”¯æŒä¸‰ç§æ—¶é—´è¯­ä¹‰ï¼š

1. **Event Time (äº‹ä»¶æ—¶é—´)**: äº‹ä»¶å®é™…å‘ç”Ÿçš„æ—¶é—´
2. **Processing Time (å¤„ç†æ—¶é—´)**: äº‹ä»¶è¢«å¤„ç†çš„æ—¶é—´
3. **Ingestion Time (æ‘„å…¥æ—¶é—´)**: äº‹ä»¶è¿›å…¥Flinkçš„æ—¶é—´

```java
/**
 * æ—¶é—´è¯­ä¹‰è®¾ç½®
 * 
 * @author erik.zhou
 */
public class TimeCharacteristicExample {
    
    public static void main(String[] args) throws Exception {
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        
        // Flink 1.12+é»˜è®¤ä½¿ç”¨Event Time
        // æ— éœ€æ˜¾å¼è®¾ç½®
        
        env.execute();
    }
}
```

#### 2.2.2 æ°´å° (Watermark)

æ°´å°æ˜¯Flinkå¤„ç†ä¹±åºäº‹ä»¶çš„æœºåˆ¶ï¼Œè¡¨ç¤º"æ—¶é—´æˆ³å°äºæ°´å°çš„äº‹ä»¶éƒ½å·²åˆ°è¾¾"ã€‚

```java
import org.apache.flink.api.common.eventtime.WatermarkStrategy;
import org.apache.flink.api.common.eventtime.SerializableTimestampAssigner;
import java.time.Duration;

/**
 * æ°´å°ç­–ç•¥ç¤ºä¾‹
 * 
 * @author erik.zhou
 */
public class WatermarkExample {
    
    // äº‹ä»¶ç±»
    public static class Event {
        public String id;
        public long timestamp;
        public String data;
        
        public Event(String id, long timestamp, String data) {
            this.id = id;
            this.timestamp = timestamp;
            this.data = data;
        }
    }
    
    public static void main(String[] args) throws Exception {
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        
        DataStream<Event> events = env.addSource(new EventSource());
        
        // æ–¹å¼1: å•è°ƒé€’å¢æ°´å° (äº‹ä»¶æ—¶é—´ä¸¥æ ¼é€’å¢)
        DataStream<Event> withWatermarks1 = events.assignTimestampsAndWatermarks(
            WatermarkStrategy.<Event>forMonotonousTimestamps()
                .withTimestampAssigner((event, timestamp) -> event.timestamp)
        );
        
        // æ–¹å¼2: å›ºå®šå»¶è¿Ÿæ°´å° (å…è®¸æœ€å¤š5ç§’çš„ä¹±åº)
        DataStream<Event> withWatermarks2 = events.assignTimestampsAndWatermarks(
            WatermarkStrategy.<Event>forBoundedOutOfOrderness(Duration.ofSeconds(5))
                .withTimestampAssigner((event, timestamp) -> event.timestamp)
        );
        
        // æ–¹å¼3: è‡ªå®šä¹‰æ°´å°ç­–ç•¥
        DataStream<Event> withWatermarks3 = events.assignTimestampsAndWatermarks(
            WatermarkStrategy.<Event>forGenerator(ctx -> new CustomWatermarkGenerator())
                .withTimestampAssigner((event, timestamp) -> event.timestamp)
        );
        
        env.execute("Watermark Example");
    }
}
```

### 2.3 çª—å£æ“ä½œ ğŸ”¥

çª—å£å°†æ— é™æµåˆ‡åˆ†æˆæœ‰é™çš„æ•°æ®å—è¿›è¡Œå¤„ç†ã€‚

#### 2.3.1 çª—å£ç±»å‹

**æ—¶é—´çª—å£**:
```java
import org.apache.flink.streaming.api.windowing.assigners.*;
import org.apache.flink.streaming.api.windowing.time.Time;

/**
 * æ—¶é—´çª—å£ç¤ºä¾‹
 * 
 * @author erik.zhou
 */
public class TimeWindowExample {
    
    public static void main(String[] args) throws Exception {
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        
        DataStream<Tuple2<String, Integer>> input = env.fromElements(
            Tuple2.of("a", 1),
            Tuple2.of("b", 2),
            Tuple2.of("a", 3)
        );
        
        // 1. æ»šåŠ¨çª—å£ (Tumbling Window)
        // æ¯5ç§’ä¸€ä¸ªçª—å£ï¼Œçª—å£ä¹‹é—´ä¸é‡å 
        DataStream<Tuple2<String, Integer>> tumbling = input
            .keyBy(tuple -> tuple.f0)
            .window(TumblingEventTimeWindows.of(Time.seconds(5)))
            .sum(1);
        
        // 2. æ»‘åŠ¨çª—å£ (Sliding Window)
        // çª—å£å¤§å°10ç§’ï¼Œæ¯5ç§’æ»‘åŠ¨ä¸€æ¬¡
        DataStream<Tuple2<String, Integer>> sliding = input
            .keyBy(tuple -> tuple.f0)
            .window(SlidingEventTimeWindows.of(Time.seconds(10), Time.seconds(5)))
            .sum(1);
        
        // 3. ä¼šè¯çª—å£ (Session Window)
        // é—´éš”è¶…è¿‡5ç§’åˆ™å¼€å¯æ–°çª—å£
        DataStream<Tuple2<String, Integer>> session = input
            .keyBy(tuple -> tuple.f0)
            .window(EventTimeSessionWindows.withGap(Time.seconds(5)))
            .sum(1);
        
        // 4. å…¨å±€çª—å£ (Global Window)
        // éœ€è¦è‡ªå®šä¹‰è§¦å‘å™¨
        DataStream<Tuple2<String, Integer>> global = input
            .keyBy(tuple -> tuple.f0)
            .window(GlobalWindows.create())
            .trigger(CountTrigger.of(100))
            .sum(1);
        
        env.execute("Time Window Example");
    }
}
```

**è®¡æ•°çª—å£**:
```java
/**
 * è®¡æ•°çª—å£ç¤ºä¾‹
 * 
 * @author erik.zhou
 */
public class CountWindowExample {
    
    public static void main(String[] args) throws Exception {
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        
        DataStream<Tuple2<String, Integer>> input = env.fromElements(
            Tuple2.of("a", 1),
            Tuple2.of("a", 2),
            Tuple2.of("a", 3)
        );
        
        // æ»šåŠ¨è®¡æ•°çª—å£: æ¯3ä¸ªå…ƒç´ ä¸€ä¸ªçª—å£
        DataStream<Tuple2<String, Integer>> tumbling = input
            .keyBy(tuple -> tuple.f0)
            .countWindow(3)
            .sum(1);
        
        // æ»‘åŠ¨è®¡æ•°çª—å£: çª—å£å¤§å°5ï¼Œæ¯2ä¸ªå…ƒç´ æ»‘åŠ¨ä¸€æ¬¡
        DataStream<Tuple2<String, Integer>> sliding = input
            .keyBy(tuple -> tuple.f0)
            .countWindow(5, 2)
            .sum(1);
        
        env.execute("Count Window Example");
    }
}
```

#### 2.3.2 çª—å£å‡½æ•°

```java
import org.apache.flink.streaming.api.functions.windowing.WindowFunction;
import org.apache.flink.streaming.api.windowing.windows.TimeWindow;
import org.apache.flink.util.Collector;

/**
 * çª—å£å‡½æ•°ç¤ºä¾‹
 * 
 * @author erik.zhou
 */
public class WindowFunctionExample {
    
    public static void main(String[] args) throws Exception {
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        
        DataStream<Tuple2<String, Integer>> input = env.socketTextStream("localhost", 9999)
            .map(line -> {
                String[] parts = line.split(",");
                return Tuple2.of(parts[0], Integer.parseInt(parts[1]));
            })
            .returns(Types.TUPLE(Types.STRING, Types.INT));
        
        // 1. ReduceFunction: å¢é‡èšåˆ
        DataStream<Tuple2<String, Integer>> reduced = input
            .keyBy(tuple -> tuple.f0)
            .window(TumblingEventTimeWindows.of(Time.seconds(5)))
            .reduce((t1, t2) -> Tuple2.of(t1.f0, t1.f1 + t2.f1));
        
        // 2. AggregateFunction: å¢é‡èšåˆ (æ›´çµæ´»)
        DataStream<Double> aggregated = input
            .keyBy(tuple -> tuple.f0)
            .window(TumblingEventTimeWindows.of(Time.seconds(5)))
            .aggregate(new AverageAggregate());
        
        // 3. ProcessWindowFunction: å…¨é‡èšåˆ (å¯è®¿é—®çª—å£å…ƒæ•°æ®)
        DataStream<String> processed = input
            .keyBy(tuple -> tuple.f0)
            .window(TumblingEventTimeWindows.of(Time.seconds(5)))
            .process(new MyProcessWindowFunction());
        
        // 4. å¢é‡èšåˆ + å…¨é‡èšåˆ (æ€§èƒ½æœ€ä¼˜)
        DataStream<String> combined = input
            .keyBy(tuple -> tuple.f0)
            .window(TumblingEventTimeWindows.of(Time.seconds(5)))
            .aggregate(new AverageAggregate(), new MyProcessWindowFunction());
        
        env.execute("Window Function Example");
    }
    
    // è‡ªå®šä¹‰ProcessWindowFunction
    public static class MyProcessWindowFunction 
            extends ProcessWindowFunction<Tuple2<String, Integer>, String, String, TimeWindow> {
        
        @Override
        public void process(String key, Context context, 
                          Iterable<Tuple2<String, Integer>> elements, 
                          Collector<String> out) {
            int count = 0;
            int sum = 0;
            for (Tuple2<String, Integer> element : elements) {
                count++;
                sum += element.f1;
            }
            
            long windowStart = context.window().getStart();
            long windowEnd = context.window().getEnd();
            
            out.collect(String.format(
                "Key: %s, Window: [%d-%d], Count: %d, Sum: %d",
                key, windowStart, windowEnd, count, sum
            ));
        }
    }
}
```

### 2.4 çŠ¶æ€ç®¡ç† (âš ï¸ éš¾ç‚¹)

Flinkçš„çŠ¶æ€ç®¡ç†æ˜¯å…¶æ ¸å¿ƒä¼˜åŠ¿ä¹‹ä¸€ã€‚

#### 2.4.1 çŠ¶æ€ç±»å‹

Flinkæ”¯æŒä¸¤ç§çŠ¶æ€ï¼š

1. **Keyed State**: ä¸keyå…³è”çš„çŠ¶æ€
   - ValueState: å•ä¸ªå€¼
   - ListState: å€¼åˆ—è¡¨
   - MapState: é”®å€¼å¯¹æ˜ å°„
   - ReducingState: èšåˆçŠ¶æ€
   - AggregatingState: èšåˆçŠ¶æ€

2. **Operator State**: ä¸ç®—å­å®ä¾‹å…³è”çš„çŠ¶æ€
   - ListState: å€¼åˆ—è¡¨
   - UnionListState: å€¼åˆ—è¡¨ (é‡åˆ†å¸ƒæ—¶åˆå¹¶)
   - BroadcastState: å¹¿æ’­çŠ¶æ€

#### 2.4.2 ä½¿ç”¨Keyed State

```java
import org.apache.flink.api.common.state.*;
import org.apache.flink.api.common.typeinfo.Types;
import org.apache.flink.configuration.Configuration;
import org.apache.flink.streaming.api.functions.KeyedProcessFunction;
import org.apache.flink.util.Collector;

/**
 * Keyed Stateç¤ºä¾‹
 * 
 * @author erik.zhou
 */
public class KeyedStateExample {
    
    public static void main(String[] args) throws Exception {
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        
        DataStream<Tuple2<String, Integer>> input = env.socketTextStream("localhost", 9999)
            .map(line -> {
                String[] parts = line.split(",");
                return Tuple2.of(parts[0], Integer.parseInt(parts[1]));
            })
            .returns(Types.TUPLE(Types.STRING, Types.INT));
        
        DataStream<String> result = input
            .keyBy(tuple -> tuple.f0)
            .process(new StatefulProcessFunction());
        
        result.print();
        
        env.execute("Keyed State Example");
    }
    
    // æœ‰çŠ¶æ€çš„ProcessFunction
    public static class StatefulProcessFunction 
            extends KeyedProcessFunction<String, Tuple2<String, Integer>, String> {
        
        // ValueState: å­˜å‚¨å•ä¸ªå€¼
        private ValueState<Integer> countState;
        
        // ListState: å­˜å‚¨åˆ—è¡¨
        private ListState<Integer> historyState;
        
        // MapState: å­˜å‚¨é”®å€¼å¯¹
        private MapState<String, Integer> mapState;
        
        @Override
        public void open(Configuration parameters) {
            // åˆå§‹åŒ–ValueState
            ValueStateDescriptor<Integer> countDescriptor = 
                new ValueStateDescriptor<>("count", Integer.class);
            countState = getRuntimeContext().getState(countDescriptor);
            
            // åˆå§‹åŒ–ListState
            ListStateDescriptor<Integer> historyDescriptor = 
                new ListStateDescriptor<>("history", Integer.class);
            historyState = getRuntimeContext().getListState(historyDescriptor);
            
            // åˆå§‹åŒ–MapState
            MapStateDescriptor<String, Integer> mapDescriptor = 
                new MapStateDescriptor<>("map", String.class, Integer.class);
            mapState = getRuntimeContext().getMapState(mapDescriptor);
        }
        
        @Override
        public void processElement(Tuple2<String, Integer> value, Context ctx, Collector<String> out) 
                throws Exception {
            // ä½¿ç”¨ValueState
            Integer currentCount = countState.value();
            if (currentCount == null) {
                currentCount = 0;
            }
            currentCount += value.f1;
            countState.update(currentCount);
            
            // ä½¿ç”¨ListState
            historyState.add(value.f1);
            
            // ä½¿ç”¨MapState
            mapState.put(value.f0, value.f1);
            
            out.collect(String.format("Key: %s, Count: %d", value.f0, currentCount));
        }
    }
}
```

### 2.5 Checkpointå’Œå®¹é”™æœºåˆ¶ ğŸ”¥

Flinké€šè¿‡Checkpointæœºåˆ¶å®ç°ç²¾ç¡®ä¸€æ¬¡è¯­ä¹‰ã€‚

```java
/**
 * Checkpointé…ç½®ç¤ºä¾‹
 * 
 * @author erik.zhou
 */
public class CheckpointExample {
    
    public static void main(String[] args) throws Exception {
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        
        // å¯ç”¨Checkpointï¼Œæ¯5ç§’ä¸€æ¬¡
        env.enableCheckpointing(5000);
        
        // Checkpointé…ç½®
        CheckpointConfig config = env.getCheckpointConfig();
        
        // è®¾ç½®Checkpointæ¨¡å¼ (EXACTLY_ONCE æˆ– AT_LEAST_ONCE)
        config.setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE);
        
        // Checkpointè¶…æ—¶æ—¶é—´
        config.setCheckpointTimeout(60000);
        
        // æœ€å°é—´éš”æ—¶é—´
        config.setMinPauseBetweenCheckpoints(500);
        
        // æœ€å¤§å¹¶å‘Checkpointæ•°
        config.setMaxConcurrentCheckpoints(1);
        
        // ä½œä¸šå–æ¶ˆæ—¶ä¿ç•™Checkpoint
        config.setExternalizedCheckpointCleanup(
            CheckpointConfig.ExternalizedCheckpointCleanup.RETAIN_ON_CANCELLATION
        );
        
        // è®¾ç½®State Backend
        env.setStateBackend(new HashMapStateBackend());
        env.getCheckpointConfig().setCheckpointStorage("hdfs://namenode:9000/flink/checkpoints");
        
        env.execute("Checkpoint Example");
    }
}
```

## ğŸ’» å®æˆ˜åº”ç”¨

### 3.1 å®æ—¶WordCount

```java
/**
 * Flinkå®æ—¶WordCount
 * 
 * @author erik.zhou
 */
public class FlinkWordCount {
    
    public static void main(String[] args) throws Exception {
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        
        // ä»Socketè¯»å–æ•°æ®
        DataStream<String> text = env.socketTextStream("localhost", 9999);
        
        // å¤„ç†é€»è¾‘
        DataStream<Tuple2<String, Integer>> wordCounts = text
            .flatMap((String line, Collector<Tuple2<String, Integer>> out) -> {
                for (String word : line.split("\\s+")) {
                    out.collect(Tuple2.of(word, 1));
                }
            })
            .returns(Types.TUPLE(Types.STRING, Types.INT))
            .keyBy(tuple -> tuple.f0)
            .sum(1);
        
        // è¾“å‡ºç»“æœ
        wordCounts.print();
        
        env.execute("Flink WordCount");
    }
}
```

### 3.2 ä¸Spring Booté›†æˆ

**Mavenä¾èµ–**:
```xml
<dependency>
    <groupId>org.apache.flink</groupId>
    <artifactId>flink-streaming-java</artifactId>
    <version>1.18.0</version>
</dependency>
<dependency>
    <groupId>org.apache.flink</groupId>
    <artifactId>flink-clients</artifactId>
    <version>1.18.0</version>
</dependency>
```

**é…ç½®ç±»**:
```java
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.springframework.context.annotation.Bean;
import org.springframework.context.annotation.Configuration;

/**
 * Flinké…ç½®ç±»
 * 
 * @author erik.zhou
 */
@Configuration
public class FlinkConfig {
    
    @Bean
    public StreamExecutionEnvironment streamExecutionEnvironment() {
        StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();
        env.enableCheckpointing(5000);
        return env;
    }
}
```

## âœ¨ æœ€ä½³å®è·µ

### 4.1 æ€§èƒ½ä¼˜åŒ–

1. **åˆç†è®¾ç½®å¹¶è¡Œåº¦**
2. **ä½¿ç”¨å¼‚æ­¥I/O**
3. **å¯ç”¨å¯¹è±¡é‡ç”¨**
4. **é€‰æ‹©åˆé€‚çš„State Backend**
5. **ä¼˜åŒ–Checkpointé…ç½®**

### 4.2 ç›‘æ§ä¸è°ƒä¼˜

- ä½¿ç”¨Flink Web UIç›‘æ§ä½œä¸š
- å…³æ³¨åå‹ (Backpressure)
- ç›‘æ§Checkpointæ—¶é—´
- ä¼˜åŒ–ç®—å­é“¾ (Operator Chaining)

## â“ å¸¸è§é—®é¢˜

### Q1: Flinké€‚åˆä»€ä¹ˆåœºæ™¯ï¼Ÿ

**A**: 
- å®æ—¶æ•°æ®åˆ†æ
- äº‹ä»¶é©±åŠ¨åº”ç”¨
- å¤æ‚äº‹ä»¶å¤„ç†
- æµå¼æœºå™¨å­¦ä¹ 

### Q2: å¦‚ä½•é€‰æ‹©State Backendï¼Ÿ

**A**:
- **HashMapStateBackend**: å°çŠ¶æ€ï¼Œå¿«é€Ÿè®¿é—®
- **EmbeddedRocksDBStateBackend**: å¤§çŠ¶æ€ï¼Œæ”¯æŒå¢é‡Checkpoint

## ğŸ”— ç›¸å…³èµ„æº

- [Apache Flinkå®˜ç½‘](https://flink.apache.org/)
- [Flinkæ–‡æ¡£](https://nightlies.apache.org/flink/flink-docs-stable/)
- [Flinkä¸­æ–‡ç¤¾åŒº](https://flink-china.org/)

## ğŸ“ å­¦ä¹ æ£€æŸ¥æ¸…å•

- [ ] ç†è§£Flinkçš„æ ¸å¿ƒæ¶æ„
- [ ] æŒæ¡DataStream API
- [ ] ç†è§£äº‹ä»¶æ—¶é—´å’Œæ°´å°
- [ ] æŒæ¡çª—å£æ“ä½œ
- [ ] ç†è§£çŠ¶æ€ç®¡ç†
- [ ] äº†è§£Checkpointæœºåˆ¶
- [ ] èƒ½å¤Ÿåœ¨Javaé¡¹ç›®ä¸­é›†æˆFlink

---

**@author** erik.zhou
**æœ€åæ›´æ–°**: 2024-01-04
**æ–‡æ¡£ç‰ˆæœ¬**: 1.0
**æ–‡æ¡£æ¥æº**: Apache Flinkå®˜æ–¹æ–‡æ¡£ (Context7)
